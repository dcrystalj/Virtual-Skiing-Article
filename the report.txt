1. Introduction

The interactive installation "Virtual skiing" enables a visual immersion into the feelings of gliding on snow through a winter landscape. The computer rendered winter landscape is displayed over the entire wall in front of the skier. As on real skis you can regulate the speed of descent by changing the posture of your body so that the air resistance is decreased or increased. By shifting the weight of your body to the right or left ski you can make turns down the slope between the snow capped trees. The interface to the virtual world is implemented by computer vision techniques which capture the posture of the skier’s body.

2. Software overview

2.1 Goal of the project

The goal of the project is to provide the user a virtual skiing experience. To do so, at least the following needs to be done:

- track body movement of the user
- display a virtual 3D environment on a screen

To fulfill the requirement, Miscrosoft Kinect and Unity 3D game engine is used.

2.2 Kinect

2.2.1 Overview

Kinect is the most convienent body movement tracking hardware we can find in the market, it thus becomes the tool for our project. The Kinect sensor haveo one RGB camera and two Infra-red sensors, allowing it to track movement to/from any direction in a 3D space. 

2.2.2 Code

By examining the sample code, a skeleton of user is made using C#. A skeleton consist of nodes and lines, nodes representing the the joints of the user, lines representing the limbs/body of the user. By comparing the positions nodes, we can capture the user's movement and turn them into inputs in the game.There are 2 main types of input in the skiing game, one controls the direction and the other controls the speed of skiing.

2.2.3 Directions

To control the direction of ski, user need to band their body left or right to turn, or stay in the middle to go straight. A simple method is used to extract this particular movement by the user, we simply compare the nodes on both shoulders. The data obtained is then threasholded into only 3 inputs, left, middle and right. 

2.2.4 Speed

The user need to squat to increase the speed, and detection of squatting is needed. When squatting, the position of the node on hip is changing obviously. So, the node on hip is used to determine whether the user is squatting or not.

2.3. Unity 3D game engine - written by Tomaz

3. developing process

3.1 Planning

3.1.1 Mindmap

A mindmap is made to record all the ideas about the project. It gives the team some guide and direction to work on. This is also the step where we know each team member's strength and weakness, leads to better allocation of work later on. 

3.1.2 Research

At the beginning of the project, none of the team member knows anything about programming on Kinect, it is the main focus of search. We found that Kinect SDK is essential in coding the sensor, it comes together with Kinect studio and a developer toolkit. Kinect studio is just for testing and the developer toolkit is a package of code examples.

For the displaying of the virtual skiing world, it took us almost no time to search for game engine, one of the team member knows how to use Unity 3D, certainly this becomes your choice of game engine. 

3.1.3 Divide the work

The work of the project can be divided into two main parts, the input(Kinect) and output(the display). Chin Chung will work on Kinect, figure out how it works; Tomaz will work on the game engine, create a virtual 3D world for the user to ski on. 

3.2 work on the project (Unity) - written by Tomaz

3.3 work on the project (Kinect) - written by Chin Chung

The first attemt to work on Kinect was a failure, not until I start working on it, I didn't notice the underlying problems. I did get the skeleton of the user, retrieving some data from it, but they are not very useful. I faced three main problems in this part. 

3.3.1 C# language

I did learn several languages before, but not C#. When I read the code, I understand them in a very low level, I recognize almost all the syntex, the loops, conditionals, declarations... etc. It took me really a lot of time to get to a higher level of understanding. The documentations from Microsoft was not very useful, it maybe enough for an experienced C# programmer, not for me. 

3.3.2 Mathematics

After a lot of reading, I finally locate the part where the orientation of the nodes/joints are stored. The orientations of the nodes are expressed in rotation quaternions , an absolutely alien term for me. I checked the documentation, wikipedia and other sites, they all explain it is a very mathematical way. The main direction I studied is software engineering, the mathematics they are using are far beyond my level. I just leave the output in the form of rotation quaternion.

3.3.3 The developing environment

I used the Microsoft visual studio in the part, mainly because most tutorials on Kinect are also on this environment. Problem comes when my part needs to merge with the game engine, I have no idea how to do it. Just importing the scripts in visual studio was not enough, the scripts will not run automatically. Scripts need to link to game objects in order to get running. Also the displaying machanism is very different in Visual Studio and Unity 3D, I don't know how to translate the code.

3.3 rework

A replan is needed because the Kinect part and the Unity 3D part of the project was not mergeable. Another research is done to find Kinect code example directly in Unity 3D, not in Visual Studio. 

3.3.1 Kinect in Unity 3D

Code example was found in Unity 3D wiki, this time the whole Kinect part is coded only in the game engine. Work done in Visual Studio is repeated in Unity 3D, it was a lot smoother than before because of the experience gained. Instead of the rotational quaternion, a simpular axis system is used to compare the postions of the Joints. 

3.3.2 C# and Javascript

The code is until not fully compatable, the graphics part uses Javascript and the Kinect part uses C#. A way to transfer data between scripts in two langauges is found, and the problem is fully solved.

3.4 ending



4. conclutions

4.1 schedule (planned vs read)

5. references